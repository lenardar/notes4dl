{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127de958",
   "metadata": {},
   "source": [
    "# 用于预训练词嵌入的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e707f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d23dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载 http://d2l-data.s3-accelerate.amazonaws.com/ptb.zip ...\n",
      "正在解压 ./data/ptb.zip...\n",
      "\n",
      "# sentences数: 42068\n",
      "第一个句子: ['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter']\n",
      "第二个句子: ['pierre', '<unk>', 'N', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', 'N']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import hashlib\n",
    "import zipfile\n",
    "import collections\n",
    "import torch\n",
    "\n",
    "# --- 模拟 d2l 的数据下载与解压功能 ---\n",
    "\n",
    "# 1. 定义数据中心字典，替代 d2l.DATA_HUB\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "DATA_HUB['ptb'] = (DATA_URL + 'ptb.zip',\n",
    "                   '319d85e578af0cdc590547f26231e4e31cdf1e42')\n",
    "\n",
    "def download_extract(name, cache_dir=os.path.join('.', 'data')):\n",
    "    \"\"\"\n",
    "    一个与 d2l.download_extract 동名的独立函数，用于下载和解压数据。\n",
    "    \"\"\"\n",
    "    # 从 DATA_HUB 获取 URL 和哈希值\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    \n",
    "    # 确保缓存目录存在\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    zip_filepath = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    \n",
    "    # --- 下载逻辑 ---\n",
    "    if not os.path.exists(zip_filepath):\n",
    "        print(f'正在下载 {url} ...')\n",
    "        try:\n",
    "            r = requests.get(url, stream=True, verify=True)\n",
    "            r.raise_for_status()\n",
    "            with open(zip_filepath, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        except Exception as e:\n",
    "            print(f\"下载出错: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # --- 验证逻辑 ---\n",
    "    with open(zip_filepath, 'rb') as f:\n",
    "        sha1 = hashlib.sha1()\n",
    "        sha1.update(f.read())\n",
    "        if sha1.hexdigest() != sha1_hash:\n",
    "            print(f\"文件哈希值不匹配: {zip_filepath}\")\n",
    "            return None\n",
    "    \n",
    "    # --- 解压逻辑 ---\n",
    "    final_data_dir = os.path.join(cache_dir, name)\n",
    "    if not os.path.exists(final_data_dir):\n",
    "        print(f'正在解压 {zip_filepath}...')\n",
    "        with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.dirname(zip_filepath))\n",
    "    \n",
    "    return final_data_dir\n",
    "\n",
    "\n",
    "#@save\n",
    "def read_ptb():\n",
    "    \"\"\"将PTB数据集加载到文本行的列表中\"\"\"\n",
    "    # 唯一的改动：调用我们自己的 download_extract 函数\n",
    "    data_dir = download_extract('ptb')\n",
    "    if not data_dir:\n",
    "        print(\"无法获取PTB数据目录，程序终止。\")\n",
    "        return []\n",
    "\n",
    "    # 以下文件读取逻辑保持不变\n",
    "    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n') if line]\n",
    "\n",
    "\n",
    "sentences = read_ptb()\n",
    "print(f'\\n# sentences数: {len(sentences)}')\n",
    "\n",
    "# 打印前两个句子作为示例\n",
    "if len(sentences) > 1:\n",
    "    print(f'第一个句子: {sentences[0]}')\n",
    "    print(f'第二个句子: {sentences[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39da139c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 6719'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "\n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "\n",
    "vocab = Vocab(sentences, min_freq=10)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a8ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def subsample(sentences, vocab):\n",
    "    \"\"\"下采样高频词\"\"\"\n",
    "    # 排除未知词元'<unk>'\n",
    "    sentences = [[token for token in line if vocab[token] != vocab.unk]\n",
    "                 for line in sentences]\n",
    "    counter = count_corpus(sentences)\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # 如果在下采样期间保留词元，则返回True\n",
    "    def keep(token):\n",
    "        return(random.uniform(0, 1) <\n",
    "               math.sqrt(1e-4 / counter[token] * num_tokens))\n",
    "\n",
    "    return ([[token for token in line if keep(token)] for line in sentences],\n",
    "            counter)\n",
    "\n",
    "subsampled, counter = subsample(sentences, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c42f79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random # 用于生成示例数据\n",
    "\n",
    "def show_list_len_pair_hist(labels, xlabel, ylabel, list1, list2):\n",
    "    \"\"\"\n",
    "    绘制两个列表的元素长度分布的直方图，用于对比。\n",
    "    此函数为 d2l.show_list_len_pair_hist 的替代实现。\n",
    "    \n",
    "    参数:\n",
    "    labels (list of str): 两个分布的标签，例如 ['origin', 'subsampled']。\n",
    "    xlabel (str): x轴的标签。\n",
    "    ylabel (str): y轴的标签。\n",
    "    list1 (list of list): 第一个数据列表。\n",
    "    list2 (list of list): 第二个数据列表。\n",
    "    \"\"\"\n",
    "    # 1. 计算每个列表中元素的长度\n",
    "    lengths1 = [len(item) for item in list1]\n",
    "    lengths2 = [len(item) for item in list2]\n",
    "    \n",
    "    # 2. 设置画布大小\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    # 3. 确定一个合适的、能覆盖所有数据的 Bins（分箱）范围\n",
    "    # 这样可以确保两个直方图的x轴是对齐的\n",
    "    try:\n",
    "        max_len = max(max(lengths1), max(lengths2))\n",
    "    except ValueError: # 处理空列表的情况\n",
    "        max_len = 10\n",
    "    bins = np.arange(0, max_len + 2) - 0.5 # 让整数值位于柱子中央\n",
    "    \n",
    "    # 4. 在同一个坐标轴上绘制两个直方图\n",
    "    # 使用 alpha 参数设置透明度，以便观察重叠部分\n",
    "    plt.hist(lengths1, bins=bins, alpha=0.6, label=labels[0], edgecolor='gray')\n",
    "    plt.hist(lengths2, bins=bins, alpha=0.6, label=labels[1], edgecolor='gray')\n",
    "    \n",
    "    # 5. 添加标签、标题、图例和网格\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.title('Comparison of Sequence Lengths Distribution')\n",
    "    \n",
    "    # 6. 显示图表\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# 原来的调用方式:\n",
    "# d2l.show_list_len_pair_hist(\n",
    "#     ['origin', 'subsampled'], '# tokens per sentence',\n",
    "#     'count', sentences, subsampled);\n",
    "\n",
    "# 现在调用我们自己实现的函数:\n",
    "show_list_len_pair_hist(\n",
    "    ['origin', 'subsampled'], '# tokens per sentence',\n",
    "    'count', sentences, subsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa163b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"the\"的数量：之前=50770, 之后=2053'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return (f'\"{token}\"的数量：'\n",
    "            f'之前={sum([l.count(token) for l in sentences])}, '\n",
    "            f'之后={sum([l.count(token) for l in subsampled])}')\n",
    "\n",
    "compare_counts('the')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d41b00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"join\"的数量：之前=45, 之后=45'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts('join')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580d6d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [71, 392, 2115, 274, 406], [5277, 3054, 1580]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [vocab[line] for line in subsampled]\n",
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff377f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    \"\"\"返回跳元模型中的中心词和上下文词\"\"\"\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # 要形成“中心词-上下文词”对，每个句子至少需要有2个词\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # 上下文窗口中间i\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size)))\n",
    "            # 从上下文词中排除中心词\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2ca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集 [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "中心词 0 的上下文词是 [1, 2]\n",
      "中心词 1 的上下文词是 [0, 2]\n",
      "中心词 2 的上下文词是 [1, 3]\n",
      "中心词 3 的上下文词是 [2, 4]\n",
      "中心词 4 的上下文词是 [3, 5]\n",
      "中心词 5 的上下文词是 [3, 4, 6]\n",
      "中心词 6 的上下文词是 [5]\n",
      "中心词 7 的上下文词是 [8]\n",
      "中心词 8 的上下文词是 [7, 9]\n",
      "中心词 9 的上下文词是 [7, 8]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)), list(range(7, 10))]\n",
    "print('数据集', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)):\n",
    "    print('中心词', center, '的上下文词是', context)\n",
    "\n",
    "# 数据集 [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
    "# 中心词 0 的上下文词是 [1, 2]\n",
    "# 中心词 1 的上下文词是 [0, 2]\n",
    "# 中心词 2 的上下文词是 [1, 3]\n",
    "# 中心词 3 的上下文词是 [2, 4]\n",
    "# 中心词 4 的上下文词是 [3, 5]\n",
    "# 中心词 5 的上下文词是 [3, 4, 6]\n",
    "# 中心词 6 的上下文词是 [5]\n",
    "# 中心词 7 的上下文词是 [8]\n",
    "# 中心词 8 的上下文词是 [7, 9]\n",
    "# 中心词 9 的上下文词是 [7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20fb579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# “中心词-上下文词对”的数量: 1501718'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "f'# “中心词-上下文词对”的数量: {sum([len(contexts) for contexts in all_contexts])}'\n",
    "\n",
    "# '# “中心词-上下文词对”的数量: 1501718'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f59707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGenerator:\n",
    "    \"\"\"根据n个采样权重在{1,...,n}中随机抽取\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        # Exclude\n",
    "        self.population = list(range(1, len(sampling_weights) + 1))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # 缓存k个随机采样结果\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36fd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 3, 3, 3, 3, 3, 2, 3, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "generator = RandomGenerator([2, 3, 4])\n",
    "[generator.draw() for _ in range(10)]\n",
    "\n",
    "# [2, 2, 3, 3, 3, 3, 3, 2, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "348b093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_negatives(all_contexts, vocab, counter, K):\n",
    "    \"\"\"返回负采样中的噪声词\"\"\"\n",
    "    # 索引为1、2、...（索引0是词表中排除的未知标记）\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n",
    "                        for i in range(1, len(vocab))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # 噪声词不能是上下文词\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, vocab, counter, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aedf4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def batchify(data):\n",
    "    \"\"\"返回带有负采样的跳元模型的小批量样本\"\"\"\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += \\\n",
    "            [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(centers).reshape((-1, 1)), torch.tensor(\n",
    "        contexts_negatives), torch.tensor(masks), torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455e16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers = tensor([[1],\n",
      "        [1]])\n",
      "contexts_negatives = tensor([[2, 2, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 3, 3, 0]])\n",
      "masks = tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]])\n",
      "labels = tensor([[1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negatives', 'masks', 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '=', data)\n",
    "\n",
    "\n",
    "# centers = tensor([[1],\n",
    "#         [1]])\n",
    "# contexts_negatives = tensor([[2, 2, 3, 3, 3, 3],\n",
    "#         [2, 2, 2, 3, 3, 0]])\n",
    "# masks = tensor([[1, 1, 1, 1, 1, 1],\n",
    "#         [1, 1, 1, 1, 1, 0]])\n",
    "# labels = tensor([[1, 1, 0, 0, 0, 0],\n",
    "#         [1, 1, 1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb7ea352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, centers, contexts, negatives):\n",
    "        assert len(centers) == len(contexts) == len(negatives)\n",
    "        self.centers = centers\n",
    "        self.contexts = contexts\n",
    "        self.negatives = negatives\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.centers[index], self.contexts[index],\n",
    "                self.negatives[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.centers)\n",
    "\n",
    "\n",
    "def load_data_ptb(batch_size, max_window_size, num_noise_words):\n",
    "    \"\"\"下载PTB数据集，然后将其加载到内存中\"\"\"\n",
    "    sentences = read_ptb()\n",
    "    vocab = Vocab(sentences, min_freq=10)\n",
    "    subsampled, counter = subsample(sentences, vocab)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "    all_centers, all_contexts = get_centers_and_contexts(\n",
    "        corpus, max_window_size)\n",
    "    all_negatives = get_negatives(\n",
    "        all_contexts, vocab, counter, num_noise_words)\n",
    "\n",
    "    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n",
    "\n",
    "    data_iter = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size, shuffle=True,\n",
    "        collate_fn=batchify)\n",
    "    return data_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d2088a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers shape: torch.Size([512, 1])\n",
      "contexts_negatives shape: torch.Size([512, 60])\n",
      "masks shape: torch.Size([512, 60])\n",
      "labels shape: torch.Size([512, 60])\n"
     ]
    }
   ],
   "source": [
    "data_iter, vocab = load_data_ptb(512, 5, 5)\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d296ce",
   "metadata": {},
   "source": [
    "# 预训练word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e980d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "import hashlib\n",
    "import zipfile\n",
    "import collections\n",
    "import torch\n",
    "\n",
    "\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "DATA_HUB['ptb'] = (DATA_URL + 'ptb.zip',\n",
    "                   '319d85e578af0cdc590547f26231e4e31cdf1e42')\n",
    "\n",
    "def download_extract(name, cache_dir=os.path.join('.', 'data')):\n",
    "    \"\"\"\n",
    "    一个与 d2l.download_extract 동名的独立函数，用于下载和解压数据。\n",
    "    \"\"\"\n",
    "    # 从 DATA_HUB 获取 URL 和哈希值\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    \n",
    "    # 确保缓存目录存在\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    zip_filepath = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    \n",
    "    # --- 下载逻辑 ---\n",
    "    if not os.path.exists(zip_filepath):\n",
    "        print(f'正在下载 {url} ...')\n",
    "        try:\n",
    "            r = requests.get(url, stream=True, verify=True)\n",
    "            r.raise_for_status()\n",
    "            with open(zip_filepath, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        except Exception as e:\n",
    "            print(f\"下载出错: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # --- 验证逻辑 ---\n",
    "    with open(zip_filepath, 'rb') as f:\n",
    "        sha1 = hashlib.sha1()\n",
    "        sha1.update(f.read())\n",
    "        if sha1.hexdigest() != sha1_hash:\n",
    "            print(f\"文件哈希值不匹配: {zip_filepath}\")\n",
    "            return None\n",
    "    \n",
    "    # --- 解压逻辑 ---\n",
    "    final_data_dir = os.path.join(cache_dir, name)\n",
    "    if not os.path.exists(final_data_dir):\n",
    "        print(f'正在解压 {zip_filepath}...')\n",
    "        with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.dirname(zip_filepath))\n",
    "    \n",
    "    return final_data_dir\n",
    "\n",
    "\n",
    "def read_ptb():\n",
    "    \"\"\"将PTB数据集加载到文本行的列表中\"\"\"\n",
    "    # 唯一的改动：调用我们自己的 download_extract 函数\n",
    "    data_dir = download_extract('ptb')\n",
    "    if not data_dir:\n",
    "        print(\"无法获取PTB数据目录，程序终止。\")\n",
    "        return []\n",
    "\n",
    "    # 以下文件读取逻辑保持不变\n",
    "    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n') if line]\n",
    "\n",
    "\n",
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "\n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "\n",
    "def subsample(sentences, vocab):\n",
    "    \"\"\"下采样高频词\"\"\"\n",
    "    # 排除未知词元'<unk>'\n",
    "    sentences = [[token for token in line if vocab[token] != vocab.unk]\n",
    "                 for line in sentences]\n",
    "    counter = count_corpus(sentences)\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # 如果在下采样期间保留词元，则返回True\n",
    "    def keep(token):\n",
    "        return(random.uniform(0, 1) <\n",
    "               math.sqrt(1e-4 / counter[token] * num_tokens))\n",
    "\n",
    "    return ([[token for token in line if keep(token)] for line in sentences],\n",
    "            counter)\n",
    "\n",
    "\n",
    "def compare_counts(token):\n",
    "    return (f'\"{token}\"的数量：'\n",
    "            f'之前={sum([l.count(token) for l in sentences])}, '\n",
    "            f'之后={sum([l.count(token) for l in subsampled])}')\n",
    "\n",
    "\n",
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    \"\"\"返回跳元模型中的中心词和上下文词\"\"\"\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # 要形成“中心词-上下文词”对，每个句子至少需要有2个词\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # 上下文窗口中间i\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size)))\n",
    "            # 从上下文词中排除中心词\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts\n",
    "\n",
    "\n",
    "class RandomGenerator:\n",
    "    \"\"\"根据n个采样权重在{1,...,n}中随机抽取\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        # Exclude\n",
    "        self.population = list(range(1, len(sampling_weights) + 1))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # 缓存k个随机采样结果\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]\n",
    "\n",
    "\n",
    "def get_negatives(all_contexts, vocab, counter, K):\n",
    "    \"\"\"返回负采样中的噪声词\"\"\"\n",
    "    # 索引为1、2、...（索引0是词表中排除的未知标记）\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n",
    "                        for i in range(1, len(vocab))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # 噪声词不能是上下文词\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "\n",
    "def batchify(data):\n",
    "    \"\"\"返回带有负采样的跳元模型的小批量样本\"\"\"\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += \\\n",
    "            [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(centers).reshape((-1, 1)), torch.tensor(\n",
    "        contexts_negatives), torch.tensor(masks), torch.tensor(labels))\n",
    "\n",
    "\n",
    "class PTBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, centers, contexts, negatives):\n",
    "        assert len(centers) == len(contexts) == len(negatives)\n",
    "        self.centers = centers\n",
    "        self.contexts = contexts\n",
    "        self.negatives = negatives\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.centers[index], self.contexts[index],\n",
    "                self.negatives[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.centers)\n",
    "\n",
    "\n",
    "def load_data_ptb(batch_size, max_window_size, num_noise_words):\n",
    "    \"\"\"下载PTB数据集，然后将其加载到内存中\"\"\"\n",
    "    sentences = read_ptb()\n",
    "    vocab = Vocab(sentences, min_freq=10)\n",
    "    subsampled, counter = subsample(sentences, vocab)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "    all_centers, all_contexts = get_centers_and_contexts(\n",
    "        corpus, max_window_size)\n",
    "    all_negatives = get_negatives(\n",
    "        all_contexts, vocab, counter, num_noise_words)\n",
    "\n",
    "    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n",
    "\n",
    "    data_iter = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size, shuffle=True,\n",
    "        collate_fn=batchify)\n",
    "    return data_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5ea2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "batch_size, max_window_size, num_noise_words = 512, 5, 5\n",
    "data_iter, vocab = load_data_ptb(batch_size, max_window_size,\n",
    "                                     num_noise_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c8862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter embedding_weight (torch.Size([20, 4]), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "embed = nn.Embedding(num_embeddings=20, embedding_dim=4)\n",
    "print(f'Parameter embedding_weight ({embed.weight.shape}, '\n",
    "      f'dtype={embed.weight.dtype})')\n",
    "\n",
    "# Parameter embedding_weight (torch.Size([20, 4]), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ea20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_and_negatives)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c5ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram(torch.ones((2, 1), dtype=torch.long),\n",
    "          torch.ones((2, 4), dtype=torch.long), embed, embed).shape\n",
    "\n",
    "# torch.Size([2, 1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b07a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidBCELoss(nn.Module):\n",
    "    # 带掩码的二元交叉熵损失\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, target, mask=None):\n",
    "        out = nn.functional.binary_cross_entropy_with_logits(\n",
    "            inputs, target, weight=mask, reduction=\"none\")\n",
    "        return out.mean(dim=1)\n",
    "\n",
    "loss = SigmoidBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda2352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9352, 1.8462])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.tensor([[1.1, -2.2, 3.3, -4.4]] * 2)\n",
    "label = torch.tensor([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]])\n",
    "mask = torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])\n",
    "loss(pred, label, mask) * mask.shape[1] / mask.sum(axis=1)\n",
    "\n",
    "# tensor([0.9352, 1.8462])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4e36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9352\n",
      "1.8462\n"
     ]
    }
   ],
   "source": [
    "def sigmd(x):\n",
    "    return -math.log(1 / (1 + math.exp(-x)))\n",
    "\n",
    "print(f'{(sigmd(1.1) + sigmd(2.2) + sigmd(-3.3) + sigmd(4.4)) / 4:.4f}')\n",
    "print(f'{(sigmd(-1.1) + sigmd(-2.2)) / 2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b15b6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "net = nn.Sequential(nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size),\n",
    "                    nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5e6b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_iter, lr, num_epochs):\n",
    "    \"\"\"不依赖d2l包的Word2Vec训练函数\"\"\"\n",
    "    # 加载必要的库\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 1. 设置设备 (GPU or CPU)\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "    print(f\"Training on {device}...\")\n",
    "\n",
    "    # 2. 初始化网络权重\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Embedding):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    net = net.to(device)\n",
    "\n",
    "    # 3. 定义优化器\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    # 4. 使用列表存储每个epoch的损失\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        total_loss, total_tokens, num_batches = 0.0, 0, len(data_iter)\n",
    "        \n",
    "        net.train() # 设置为训练模式\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 将数据移动到指定设备\n",
    "            center, context_negative, mask, label = [\n",
    "                data.to(device) for data in batch\n",
    "            ]\n",
    "            \n",
    "            # 前向传播计算预测值和损失\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "            l = (loss(pred.reshape(label.shape).float(), label.float(), mask) \n",
    "                 / mask.sum(axis=1) * mask.shape[1])\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 累加损失和处理的token数量\n",
    "            total_loss += l.sum().item()\n",
    "            total_tokens += l.numel()\n",
    "        \n",
    "        # 计算并记录当前epoch的平均损失\n",
    "        epoch_loss = total_loss / total_tokens\n",
    "        loss_history.append(epoch_loss)\n",
    "        \n",
    "        # 打印当前epoch的训练信息\n",
    "        epoch_time = time.time() - start_time\n",
    "        tokens_per_sec = total_tokens / epoch_time\n",
    "        \n",
    "        print(f'Epoch {epoch + 1:02d}/{num_epochs}, '\n",
    "              f'Loss: {epoch_loss:.4f}, '\n",
    "              f'{tokens_per_sec:.1f} tokens/sec')\n",
    "\n",
    "    print(f'\\nTraining finished. Final loss: {loss_history[-1]:.4f}')\n",
    "\n",
    "    # 绘图\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, num_epochs + 1), loss_history, marker='o')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(range(1, num_epochs + 1))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 返回损失历史记录  \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7690b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mps...\n",
      "Epoch 01/5, Loss: 0.4806, 28951.6 tokens/sec\n",
      "Epoch 02/5, Loss: 0.4254, 31270.2 tokens/sec\n",
      "Epoch 03/5, Loss: 0.4031, 29409.7 tokens/sec\n",
      "Epoch 04/5, Loss: 0.3798, 29246.7 tokens/sec\n",
      "Epoch 05/5, Loss: 0.3592, 33652.2 tokens/sec\n",
      "\n",
      "Training finished. Final loss: 0.3592\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.4805784340695549,\n",
       " 0.4254359654030575,\n",
       " 0.4031074643041177,\n",
       " 0.3797615021935807,\n",
       " 0.3592291774276477]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, num_epochs = 0.002, 5\n",
    "train(net, data_iter, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174725e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.708: desktop\n",
      "cosine sim=0.699: intel\n",
      "cosine sim=0.695: microprocessor\n"
     ]
    }
   ],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.weight.data\n",
    "    x = W[vocab[query_token]]\n",
    "    # 计算余弦相似性。增加1e-9以获得数值稳定性\n",
    "    cos = torch.mv(W, x) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
    "                                      torch.sum(x * x) + 1e-9)\n",
    "    topk = torch.topk(cos, k=k+1)[1].cpu().numpy().astype('int32')\n",
    "    for i in topk[1:]:  # 删除输入词\n",
    "        print(f'cosine sim={float(cos[i]):.3f}: {vocab.to_tokens(i)}')\n",
    "\n",
    "get_similar_tokens('chip', 3, net[0])\n",
    "\n",
    "# cosine sim=0.708: desktop\n",
    "# cosine sim=0.699: intel\n",
    "# cosine sim=0.695: microprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47682ca3",
   "metadata": {},
   "source": [
    "# 子词嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "271519a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "           'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "           '_', '[UNK]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d03e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f a s t _': 4, 'f a s t e r _': 3, 't a l l _': 5, 't a l l e r _': 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_token_freqs = {'fast_': 4, 'faster_': 3, 'tall_': 5, 'taller_': 4}\n",
    "token_freqs = {}\n",
    "for token, freq in raw_token_freqs.items():\n",
    "    token_freqs[' '.join(list(token))] = raw_token_freqs[token]\n",
    "token_freqs\n",
    "\n",
    "# {'f a s t _': 4, 'f a s t e r _': 3, 't a l l _': 5, 't a l l e r _': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1d44a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_freq_pair(token_freqs):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for token, freq in token_freqs.items():\n",
    "        symbols = token.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            # “pairs”的键是两个连续符号的元组\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "    return max(pairs, key=pairs.get)  # 具有最大值的“pairs”键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d0d4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_symbols(max_freq_pair, token_freqs, symbols):\n",
    "    symbols.append(''.join(max_freq_pair))\n",
    "    new_token_freqs = dict()\n",
    "    for token, freq in token_freqs.items():\n",
    "        new_token = token.replace(' '.join(max_freq_pair),\n",
    "                                  ''.join(max_freq_pair))\n",
    "        new_token_freqs[new_token] = token_freqs[token]\n",
    "    return new_token_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bf60dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_symbols(max_freq_pair, token_freqs, symbols):\n",
    "    symbols.append(''.join(max_freq_pair))\n",
    "    new_token_freqs = dict()\n",
    "    for token, freq in token_freqs.items():\n",
    "        new_token = token.replace(' '.join(max_freq_pair),\n",
    "                                  ''.join(max_freq_pair))\n",
    "        new_token_freqs[new_token] = token_freqs[token]\n",
    "    return new_token_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25f1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并# 1: ('t', 'a')\n",
      "合并# 2: ('ta', 'l')\n",
      "合并# 3: ('tal', 'l')\n",
      "合并# 4: ('f', 'a')\n",
      "合并# 5: ('fa', 's')\n",
      "合并# 6: ('fas', 't')\n",
      "合并# 7: ('e', 'r')\n",
      "合并# 8: ('er', '_')\n",
      "合并# 9: ('tall', '_')\n",
      "合并# 10: ('fast', '_')\n"
     ]
    }
   ],
   "source": [
    "num_merges = 10\n",
    "for i in range(num_merges):\n",
    "    max_freq_pair = get_max_freq_pair(token_freqs)\n",
    "    token_freqs = merge_symbols(max_freq_pair, token_freqs, symbols)\n",
    "    print(f'合并# {i+1}:',max_freq_pair)\n",
    "# 合并# 1: ('t', 'a')\n",
    "# 合并# 2: ('ta', 'l')\n",
    "# 合并# 3: ('tal', 'l')\n",
    "# 合并# 4: ('f', 'a')\n",
    "# 合并# 5: ('fa', 's')\n",
    "# 合并# 6: ('fas', 't')\n",
    "# 合并# 7: ('e', 'r')\n",
    "# 合并# 8: ('er', '_')\n",
    "# 合并# 9: ('tall', '_')\n",
    "# 合并# 10: ('fast', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', '[UNK]', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_', 'fast_']\n"
     ]
    }
   ],
   "source": [
    "print(symbols)\n",
    "\n",
    "# ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', '[UNK]', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_', 'fast_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fast_', 'fast er_', 'tall_', 'tall er_']\n"
     ]
    }
   ],
   "source": [
    "print(list(token_freqs.keys()))\n",
    "\n",
    "# ['fast_', 'fast er_', 'tall_', 'tall er_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07426630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_BPE(tokens, symbols):\n",
    "    outputs = []\n",
    "    for token in tokens:\n",
    "        start, end = 0, len(token)\n",
    "        cur_output = []\n",
    "        # 具有符号中可能最长子字的词元段\n",
    "        while start < len(token) and start < end:\n",
    "            if token[start: end] in symbols:\n",
    "                cur_output.append(token[start: end])\n",
    "                start = end\n",
    "                end = len(token)\n",
    "            else:\n",
    "                end -= 1\n",
    "        if start < len(token):\n",
    "            cur_output.append('[UNK]')\n",
    "        outputs.append(' '.join(cur_output))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b12d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tall e s t _', 'fa t t er_']\n"
     ]
    }
   ],
   "source": [
    "tokens = ['tallest_', 'fatter_']\n",
    "print(segment_BPE(tokens, symbols))\n",
    "\n",
    "# ['tall e s t _', 'fa t t er_']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7184e1e",
   "metadata": {},
   "source": [
    "# 词的相似性和类比任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be2fc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "443f7ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下载 GloVe 50维词向量...\n",
      "正在从 http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.50d.zip 下载 ./data/glove.6B.50d.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/glove.6B.50d.zip: 100%|██████████| 69.2M/69.2M [00:07<00:00, 9.61MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 ./data/glove.6B.50d.zip 校验成功。\n",
      "正在解压 ./data/glove.6B.50d.zip 到 ./data/glove_6b_50d...\n",
      "GloVe 50d 数据已准备好，位于: ./data/glove_6b_50d\n",
      "文件夹内容: ['glove.6B.50d']\n",
      "\n",
      "==============================\n",
      "\n",
      "下载英文维基百科数据集...\n",
      "正在从 http://d2l-data.s3-accelerate.amazonaws.com/wiki.en.zip 下载 ./data/wiki.en.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/wiki.en.zip: 100%|██████████| 2.47G/2.47G [03:55<00:00, 10.5MiB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 ./data/wiki.en.zip 校验成功。\n",
      "正在解压 ./data/wiki.en.zip 到 ./data/wiki_en...\n",
      "wiki.en 数据已准备好，位于: ./data/wiki_en\n",
      "文件夹内容: ['wiki.en']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import hashlib\n",
    "import zipfile\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_and_extract(name, cache_dir=os.path.join('.', 'data')):\n",
    "    \"\"\"\n",
    "    下载并解压预定义的数据集。\n",
    "\n",
    "    Args:\n",
    "        name (str): 数据集的名称 (e.g., 'glove.6b.50d').\n",
    "        cache_dir (str): 用于存储下载文件的本地目录。\n",
    "\n",
    "    Returns:\n",
    "        str: 解压后数据所在的文件夹路径。\n",
    "    \"\"\"\n",
    "    # 1. 定义数据信息 (URL 和 SHA-1 校验和)\n",
    "    DATA_HUB = {\n",
    "        'glove.6b.50d': ('http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.50d.zip',\n",
    "                         '0b8703943ccdb6eb788e6f091b8946e82231bc4d'),\n",
    "        'glove.6b.100d': ('http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.100d.zip',\n",
    "                          'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a'),\n",
    "        'glove.42b.300d': ('http://d2l-data.s3-accelerate.amazonaws.com/glove.42B.300d.zip',\n",
    "                           'b5116e234e9eb9076672cfeabf5469f3eec904fa'),\n",
    "        'wiki.en': ('http://d2l-data.s3-accelerate.amazonaws.com/wiki.en.zip',\n",
    "                    'c1816da3821ae9f43899be655002f6c723e91b88')\n",
    "    }\n",
    "\n",
    "    if name not in DATA_HUB:\n",
    "        raise ValueError(f\"未定义的数据集: {name}\")\n",
    "\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    dest_dir = os.path.join(cache_dir, name.replace('.', '_')) # 创建一个唯一的解压目录名\n",
    "\n",
    "    # 2. 下载文件 (如果本地不存在)\n",
    "    if not os.path.exists(fname):\n",
    "        print(f\"正在从 {url} 下载 {fname}...\")\n",
    "        try:\n",
    "            r = requests.get(url, stream=True, timeout=30)\n",
    "            r.raise_for_status() # 如果请求失败则引发异常\n",
    "            total_size = int(r.headers.get('content-length', 0))\n",
    "            \n",
    "            with open(fname, 'wb') as f, tqdm(\n",
    "                desc=fname, total=total_size, unit='iB', unit_scale=True\n",
    "            ) as bar:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "        except Exception as e:\n",
    "            if os.path.exists(fname):\n",
    "                os.remove(fname)\n",
    "            print(f\"下载错误: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # 3. 校验文件\n",
    "    sha1 = hashlib.sha1()\n",
    "    with open(fname, 'rb') as f:\n",
    "        while True:\n",
    "            data = f.read(1048576) # 1MB 块\n",
    "            if not data:\n",
    "                break\n",
    "            sha1.update(data)\n",
    "    \n",
    "    if sha1.hexdigest() != sha1_hash:\n",
    "        print(f\"SHA1 校验和不匹配。文件 {fname} 可能已损坏。\")\n",
    "        # os.remove(fname) # 可选择删除损坏的文件\n",
    "        return None\n",
    "    print(f\"文件 {fname} 校验成功。\")\n",
    "\n",
    "    # 4. 解压文件\n",
    "    if not os.path.exists(dest_dir) or not os.listdir(dest_dir):\n",
    "        print(f\"正在解压 {fname} 到 {dest_dir}...\")\n",
    "        if fname.endswith('.zip'):\n",
    "            with zipfile.ZipFile(fname, 'r') as zf:\n",
    "                zf.extractall(dest_dir)\n",
    "        elif fname.endswith(('.tar', '.gz', '.tgz')):\n",
    "             with tarfile.open(fname, 'r') as tf:\n",
    "                tf.extractall(dest_dir)\n",
    "        else:\n",
    "             print(f\"不支持的文件格式: {fname}\")\n",
    "             return fname # 如果不是压缩文件，直接返回文件路径\n",
    "    \n",
    "    return dest_dir\n",
    "\n",
    "# --- 如何使用 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"下载 GloVe 50维词向量...\")\n",
    "    glove_50d_dir = download_and_extract('glove.6b.50d')\n",
    "    if glove_50d_dir:\n",
    "        print(f\"GloVe 50d 数据已准备好，位于: {glove_50d_dir}\")\n",
    "        # 你可以列出文件来确认\n",
    "        print(\"文件夹内容:\", os.listdir(glove_50d_dir))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "    print(\"下载英文维基百科数据集...\")\n",
    "    wiki_en_dir = download_and_extract('wiki.en')\n",
    "    if wiki_en_dir:\n",
    "        print(f\"wiki.en 数据已准备好，位于: {wiki_en_dir}\")\n",
    "        print(\"文件夹内容:\", os.listdir(wiki_en_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77517dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _download_embedding_if_needed(name, cache_dir=os.path.join('.', 'data')):\n",
    "    \"\"\"\n",
    "    一个独立的辅助函数，用于下载和解压GloVe词向量。\n",
    "    该版本能自动在压缩包内查找正确的 .txt 文件名。\n",
    "    \"\"\"\n",
    "    DATA_HUB = {\n",
    "        'glove.6b.50d': ('http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.50d.zip',),\n",
    "        'glove.6b.100d': ('http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.100d.zip',)\n",
    "    }\n",
    "    \n",
    "    if name not in DATA_HUB:\n",
    "        raise ValueError(f\"未定义的数据集名称: {name}\")\n",
    "\n",
    "    url, = DATA_HUB[name]\n",
    "    \n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    zip_path = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    \n",
    "    # 首先检查最终解压出的文件是否已存在，这需要动态确定文件名\n",
    "    # 我们先假设一个文件名，如果不存在再继续\n",
    "    potential_fname = name + '.txt' # 例如 'glove.6b.50d.txt'\n",
    "    embedding_path = os.path.join(cache_dir, potential_fname)\n",
    "\n",
    "    if not os.path.exists(embedding_path):\n",
    "        print(f\"本地未找到词向量文件，开始下载和解压流程...\")\n",
    "        \n",
    "        if not os.path.exists(zip_path):\n",
    "            print(f\"正在下载 {url} ...\")\n",
    "            try:\n",
    "                r = requests.get(url, stream=True, timeout=60)\n",
    "                r.raise_for_status()\n",
    "                total_size = int(r.headers.get('content-length', 0))\n",
    "                with open(zip_path, 'wb') as f, tqdm(\n",
    "                    desc=name, total=total_size, unit='iB', unit_scale=True\n",
    "                ) as bar:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                        bar.update(len(chunk))\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if os.path.exists(zip_path): os.remove(zip_path)\n",
    "                raise IOError(f\"下载文件时出错: {e}\")\n",
    "\n",
    "        print(f\"正在解压 {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "            # ===================================================================\n",
    "            #   关键修改：不再硬编码文件名，而是自动在压缩包内查找\n",
    "            # ===================================================================\n",
    "            txt_filename = ''\n",
    "            for file_in_zip in zf.namelist():\n",
    "                if file_in_zip.lower().endswith('.txt'):\n",
    "                    txt_filename = file_in_zip\n",
    "                    break\n",
    "            \n",
    "            if not txt_filename:\n",
    "                raise IOError(f\"在 {zip_path} 中未找到 .txt 文件。\")\n",
    "            \n",
    "            # 使用找到的文件名进行解压\n",
    "            print(f\"在压缩包中找到文件: {txt_filename}, 正在解压...\")\n",
    "            zf.extract(txt_filename, cache_dir)\n",
    "            # 更新正确的最终文件路径\n",
    "            embedding_path = os.path.join(cache_dir, txt_filename)\n",
    "        \n",
    "        os.remove(zip_path)\n",
    "        print(\"下载和解压完成。\")\n",
    "    else:\n",
    "        print(f\"在本地找到已缓存的文件: {embedding_path}\")\n",
    "\n",
    "    return embedding_path\n",
    "\n",
    "\n",
    "class TokenEmbedding:\n",
    "    \"\"\"GloVe嵌入\"\"\"\n",
    "    def __init__(self, embedding_name='glove.6b.50d'):\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(embedding_name)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in\n",
    "                             enumerate(self.idx_to_token)}\n",
    "        print(f\"成功加载 '{embedding_name}'。词汇表大小: {len(self.idx_to_token)}\")\n",
    "\n",
    "    def _load_embedding(self, embedding_name):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        embedding_path = _download_embedding_if_needed(embedding_name)\n",
    "        \n",
    "        with open(embedding_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        \n",
    "        embedding_dim = len(idx_to_vec[0])\n",
    "        idx_to_vec = [[0.0] * embedding_dim] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            tokens = [tokens]\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx) for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "736fedf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本地未找到词向量文件，开始下载和解压流程...\n",
      "正在解压 ./data/glove.6B.50d.zip...\n",
      "在压缩包中找到文件: glove.6B.50d/vec.txt, 正在解压...\n",
      "下载和解压完成。\n",
      "成功加载 'glove.6b.50d'。词汇表大小: 400001\n"
     ]
    }
   ],
   "source": [
    "glove_6b50d = TokenEmbedding('glove.6b.50d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b15b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400001"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_6b50d)\n",
    "\n",
    "# 400001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f9636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, 'beautiful')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_6b50d.token_to_idx['beautiful'], glove_6b50d.idx_to_token[3367]\n",
    "\n",
    "# (3367, 'beautiful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1b30eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(W, x, k):\n",
    "    # 增加1e-9以获得数值稳定性\n",
    "    cos = torch.mv(W, x.reshape(-1,)) / (\n",
    "        torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) *\n",
    "        torch.sqrt((x * x).sum()))\n",
    "    _, topk = torch.topk(cos, k=k)\n",
    "    return topk, [cos[int(i)] for i in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "623d74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    topk, cos = knn(embed.idx_to_vec, embed[[query_token]], k + 1)\n",
    "    for i, c in zip(topk[1:], cos[1:]):  # 排除输入词\n",
    "        print(f'{embed.idx_to_token[int(i)]}：cosine相似度={float(c):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c0a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chips：cosine相似度=0.856\n",
      "intel：cosine相似度=0.749\n",
      "electronics：cosine相似度=0.749\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens('chip', 3, glove_6b50d)\n",
    "\n",
    "# chips：cosine相似度=0.856\n",
    "# intel：cosine相似度=0.749\n",
    "# electronics：cosine相似度=0.749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a7661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babies：cosine相似度=0.839\n",
      "boy：cosine相似度=0.800\n",
      "girl：cosine相似度=0.792\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens('baby', 3, glove_6b50d)\n",
    "\n",
    "# babies：cosine相似度=0.839\n",
    "# boy：cosine相似度=0.800\n",
    "# girl：cosine相似度=0.792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187becf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely：cosine相似度=0.921\n",
      "gorgeous：cosine相似度=0.893\n",
      "wonderful：cosine相似度=0.830\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens('beautiful', 3, glove_6b50d)\n",
    "\n",
    "# lovely：cosine相似度=0.921\n",
    "# gorgeous：cosine相似度=0.893\n",
    "# wonderful：cosine相似度=0.830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc68253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(token_a, token_b, token_c, embed):\n",
    "    vecs = embed[[token_a, token_b, token_c]]\n",
    "    x = vecs[1] - vecs[0] + vecs[2]\n",
    "    topk, cos = knn(embed.idx_to_vec, x, 1)\n",
    "    return embed.idx_to_token[int(topk[0])]  # 删除未知词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8294bcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daughter'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man', 'woman', 'son', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164b685",
   "metadata": {},
   "source": [
    "# 来自Transformers的双向编码器表示（BERT）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3eb5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e98c4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_and_segments(tokens_a, tokens_b=None):\n",
    "    \"\"\"获取输入序列的词元及其片段索引\"\"\"\n",
    "    tokens = ['<cls>'] + tokens_a + ['<sep>']\n",
    "    # 0和1分别标记片段A和B\n",
    "    segments = [0] * (len(tokens_a) + 2)\n",
    "    if tokens_b is not None:\n",
    "        tokens += tokens_b + ['<sep>']\n",
    "        segments += [1] * (len(tokens_b) + 1)\n",
    "    return tokens, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4bac4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "#@save\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "#@save\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "#@save\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)\n",
    "        \n",
    "\n",
    "#@save\n",
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "#@save\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # 在维度扩展后，\n",
    "        # queries的形状：(batch_size，查询的个数，1，num_hidden)\n",
    "        # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)\n",
    "        # 使用广播方式进行求和\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。\n",
    "        # scores的形状：(batch_size，查询的个数，“键-值”对的个数)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "\n",
    "\n",
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.attention = AdditiveAttention(\n",
    "            num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(\n",
    "            embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "            dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        # outputs的形状为(batch_size，num_steps，num_hiddens).\n",
    "        # hidden_state的形状为(num_layers，batch_size，num_hiddens)\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # enc_outputs的形状为(batch_size,num_steps,num_hiddens).\n",
    "        # hidden_state的形状为(num_layers,batch_size,\n",
    "        # num_hiddens)\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        # 输出X的形状为(num_steps,batch_size,embed_size)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        outputs, self._attention_weights = [], []\n",
    "        for x in X:\n",
    "            # query的形状为(batch_size,1,num_hiddens)\n",
    "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            # context的形状为(batch_size,1,num_hiddens)\n",
    "            context = self.attention(\n",
    "                query, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "            # 在特征维度上连结\n",
    "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
    "            # 将x变形为(1,batch_size,embed_size+num_hiddens)\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "            outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        # 全连接层变换后，outputs的形状为\n",
    "        # (num_steps,batch_size,vocab_size)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n",
    "                                          enc_valid_lens]\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights\n",
    "\n",
    "\n",
    "#@save\n",
    "class Seq2SeqEncoder(Encoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络编码器\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        X = self.embedding(X)\n",
    "        # 在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # 如果未提及状态，则默认为0\n",
    "        output, state = self.rnn(X)\n",
    "        # output的形状:(num_steps,batch_size,num_hiddens)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output, state\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "#@save\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "\n",
    "#@save\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "\n",
    "\n",
    "#@save\n",
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "\n",
    "#@save\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "\n",
    "#@save\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "\n",
    "\n",
    "#@save\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "\n",
    "#@save\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "\n",
    "\n",
    "#@save\n",
    "class TransformerEncoder(Encoder):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X\n",
    "    \n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state\n",
    "\n",
    "\n",
    "class TransformerDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbb5daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class BERTEncoder(nn.Module):\n",
    "    \"\"\"BERT编码器\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 max_len=1000, key_size=768, query_size=768, value_size=768,\n",
    "                 **kwargs):\n",
    "        super(BERTEncoder, self).__init__(**kwargs)\n",
    "        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.segment_embedding = nn.Embedding(2, num_hiddens)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(f\"{i}\", EncoderBlock(\n",
    "                key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                ffn_num_input, ffn_num_hiddens, num_heads, dropout, True))\n",
    "        # 在BERT中，位置嵌入是可学习的，因此我们创建一个足够长的位置嵌入参数\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,\n",
    "                                                      num_hiddens))\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens):\n",
    "        # 在以下代码段中，X的形状保持不变：（批量大小，最大序列长度，num_hiddens）\n",
    "        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n",
    "        X = X + self.pos_embedding.data[:, :X.shape[1], :]\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, valid_lens)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "391f28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4\n",
    "norm_shape, ffn_num_input, num_layers, dropout = [768], 768, 2, 0.2\n",
    "encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                      ffn_num_hiddens, num_heads, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "562402a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 768])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.randint(0, vocab_size, (2, 8))\n",
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "encoded_X = encoder(tokens, segments, None)\n",
    "encoded_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "afb3c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class MaskLM(nn.Module):\n",
    "    \"\"\"BERT的掩蔽语言模型任务\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, num_inputs=768, **kwargs):\n",
    "        super(MaskLM, self).__init__(**kwargs)\n",
    "        self.mlp = nn.Sequential(nn.Linear(num_inputs, num_hiddens),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LayerNorm(num_hiddens),\n",
    "                                 nn.Linear(num_hiddens, vocab_size))\n",
    "\n",
    "    def forward(self, X, pred_positions):\n",
    "        num_pred_positions = pred_positions.shape[1]\n",
    "        pred_positions = pred_positions.reshape(-1)\n",
    "        batch_size = X.shape[0]\n",
    "        batch_idx = torch.arange(0, batch_size)\n",
    "        # 假设batch_size=2，num_pred_positions=3\n",
    "        # 那么batch_idx是np.array（[0,0,0,1,1,1]）\n",
    "        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n",
    "        masked_X = X[batch_idx, pred_positions]\n",
    "        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n",
    "        mlm_Y_hat = self.mlp(masked_X)\n",
    "        return mlm_Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d406ddfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10000])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm = MaskLM(vocab_size, num_hiddens)\n",
    "mlm_positions = torch.tensor([[1, 5, 2], [6, 1, 5]])\n",
    "mlm_Y_hat = mlm(encoded_X, mlm_positions)\n",
    "mlm_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ecff333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class NextSentencePred(nn.Module):\n",
    "    \"\"\"BERT的下一句预测任务\"\"\"\n",
    "    def __init__(self, num_inputs, **kwargs):\n",
    "        super(NextSentencePred, self).__init__(**kwargs)\n",
    "        self.output = nn.Linear(num_inputs, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X的形状：(batchsize,num_hiddens)\n",
    "        return self.output(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a0919ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X = torch.flatten(encoded_X, start_dim=1)\n",
    "# NSP的输入形状:(batchsize，num_hiddens)\n",
    "nsp = NextSentencePred(encoded_X.shape[-1])\n",
    "nsp_Y_hat = nsp(encoded_X)\n",
    "nsp_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "efd8c3ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([2])) must be the same as input size (torch.Size([2, 2]))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m nsp_y = torch.tensor([\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m nsp_l = \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnsp_Y_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsp_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m nsp_l.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mSigmoidBCELoss.forward\u001b[39m\u001b[34m(self, inputs, target, mask)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, target, mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     out = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out.mean(dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/functional.py:3639\u001b[39m, in \u001b[36mbinary_cross_entropy_with_logits\u001b[39m\u001b[34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[39m\n\u001b[32m   3636\u001b[39m     reduction_enum = _Reduction.get_enum(reduction)\n\u001b[32m   3638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target.size() == \u001b[38;5;28minput\u001b[39m.size()):\n\u001b[32m-> \u001b[39m\u001b[32m3639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3640\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3641\u001b[39m     )\n\u001b[32m   3643\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.binary_cross_entropy_with_logits(\n\u001b[32m   3644\u001b[39m     \u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum\n\u001b[32m   3645\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Target size (torch.Size([2])) must be the same as input size (torch.Size([2, 2]))"
     ]
    }
   ],
   "source": [
    "nsp_y = torch.tensor([0, 1])\n",
    "nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "nsp_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b8ec845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class BERTModel(nn.Module):\n",
    "    \"\"\"BERT模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 max_len=1000, key_size=768, query_size=768, value_size=768,\n",
    "                 hid_in_features=768, mlm_in_features=768,\n",
    "                 nsp_in_features=768):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape,\n",
    "                    ffn_num_input, ffn_num_hiddens, num_heads, num_layers,\n",
    "                    dropout, max_len=max_len, key_size=key_size,\n",
    "                    query_size=query_size, value_size=value_size)\n",
    "        self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens),\n",
    "                                    nn.Tanh())\n",
    "        self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features)\n",
    "        self.nsp = NextSentencePred(nsp_in_features)\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens=None,\n",
    "                pred_positions=None):\n",
    "        encoded_X = self.encoder(tokens, segments, valid_lens)\n",
    "        if pred_positions is not None:\n",
    "            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n",
    "        else:\n",
    "            mlm_Y_hat = None\n",
    "        # 用于下一句预测的多层感知机分类器的隐藏层，0是“<cls>”标记的索引\n",
    "        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))\n",
    "        return encoded_X, mlm_Y_hat, nsp_Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d267d",
   "metadata": {},
   "source": [
    "# 用于预训练BERT的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36304331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f311697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本地未找到 './data/wikitext-2'，开始下载流程...\n",
      "正在从 https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.zip 下载...\n",
      "处理失败: 下载文件时出错: 404 Client Error: Not Found for url: https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "import hashlib\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _download_wikitext2(cache_dir=os.path.join('.', 'data')):\n",
    "    \"\"\"\n",
    "    一个独立的辅助函数，用于下载、校验和解压Wikitext-2数据集。\n",
    "    (已更新为有效的下载链接)\n",
    "    \"\"\"\n",
    "    # ===================================================================\n",
    "    #   关键修改：更新为 fast.ai 提供的有效链接和新的 SHA-1 校验和\n",
    "    # ===================================================================\n",
    "    url = 'https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.zip'\n",
    "    sha1_hash = 'e1b6299b999d1a35360b503ad943640b61726f55'\n",
    "    \n",
    "    # 创建缓存目录和文件路径\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    zip_path = os.path.join(cache_dir, 'wikitext-2.zip') # 使用新的文件名\n",
    "    # 解压后会生成一个名为 'wikitext-2' 的文件夹\n",
    "    dest_dir = os.path.join(cache_dir, 'wikitext-2')\n",
    "\n",
    "    # 检查本地是否有最终解压好的文件夹，如果没有则下载\n",
    "    if not os.path.exists(dest_dir):\n",
    "        print(f\"本地未找到 '{dest_dir}'，开始下载流程...\")\n",
    "        # 下载 .zip 文件\n",
    "        print(f\"正在从 {url} 下载...\")\n",
    "        try:\n",
    "            r = requests.get(url, stream=True, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            total_size = int(r.headers.get('content-length', 0))\n",
    "            with open(zip_path, 'wb') as f, tqdm(\n",
    "                desc='wikitext-2.zip', total=total_size, unit='iB', unit_scale=True\n",
    "            ) as bar:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if os.path.exists(zip_path): os.remove(zip_path)\n",
    "            raise IOError(f\"下载文件时出错: {e}\")\n",
    "\n",
    "        # 校验文件完整性\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(zip_path, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576) # 1MB 块\n",
    "                if not data: break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() != sha1_hash:\n",
    "            raise IOError(f\"文件 {zip_path} SHA1 校验和不匹配！\")\n",
    "        \n",
    "        # 解压文件\n",
    "        print(f\"正在解压 {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "            zf.extractall(cache_dir)\n",
    "        os.remove(zip_path) # 删除 .zip 文件节省空间\n",
    "        print(\"数据准备完成。\")\n",
    "    else:\n",
    "        print(f\"在本地找到已缓存的数据目录: {dest_dir}\")\n",
    "\n",
    "    return dest_dir\n",
    "\n",
    "def _read_wiki(data_dir):\n",
    "    \"\"\"\n",
    "    读取Wikitext-2数据集的训练部分，并进行预处理。\n",
    "    \"\"\"\n",
    "    file_name = os.path.join(data_dir, 'wikitext-2', 'wiki.train.tokens')\n",
    "    # 注意: fast.ai的压缩包解压后会多一层'wikitext-2'目录，所以路径要做相应调整\n",
    "    if not os.path.exists(file_name):\n",
    "         # 如果是旧的目录结构，也兼容一下\n",
    "        file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    \n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "\n",
    "# --- 如何使用 ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. 下载并准备数据，获取数据存放的目录路径\n",
    "    # 首次运行时会自动下载，之后会直接使用本地缓存\n",
    "    try:\n",
    "        data_directory = _download_wikitext2()\n",
    "        \n",
    "        # 2. 调用 _read_wiki 函数读取和处理数据\n",
    "        processed_paragraphs = _read_wiki(data_directory)\n",
    "        \n",
    "        # 3. 打印一些信息来验证结果\n",
    "        print(f\"\\n成功读取并处理了 {len(processed_paragraphs)} 个段落。\")\n",
    "        print(\"\\n示例段落:\")\n",
    "        for i, paragraph in enumerate(processed_paragraphs[:2]):\n",
    "            print(f\"  段落 {i+1}: {paragraph[:2]}\") # 打印段落的前2个句子\n",
    "            \n",
    "    except IOError as e:\n",
    "        print(f\"处理失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34c7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
