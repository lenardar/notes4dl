{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e737fb",
   "metadata": {},
   "source": [
    "学习深度学习计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cade76",
   "metadata": {},
   "source": [
    "# 层和块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96cb6e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1560, -0.0823, -0.0718,  0.0643,  0.1892,  0.2472,  0.0082,  0.0526,\n",
       "         -0.0343, -0.1716],\n",
       "        [-0.2018, -0.1450, -0.0185,  0.1079,  0.2328,  0.4292,  0.0401, -0.0474,\n",
       "         -0.0655, -0.1958]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bbf1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04557ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0898,  0.0304,  0.0319, -0.0925,  0.1536, -0.1776,  0.2120,  0.1081,\n",
       "          0.0109, -0.2248],\n",
       "        [-0.0821,  0.0304, -0.0064, -0.1893,  0.1903, -0.1745,  0.1479,  0.0573,\n",
       "         -0.0403, -0.2334]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)\n",
    "\n",
    "# tensor([[ 0.1912,  0.0413,  0.0140,  0.0509, -0.1169, -0.0441,  0.0614,  0.0376,\n",
    "#          -0.0812, -0.1776],\n",
    "#         [ 0.0929, -0.0536, -0.0730,  0.0093, -0.1146, -0.0210,  0.0392, -0.0453,\n",
    "#          -0.1113, -0.1817]], grad_fn=<AddmmBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9de1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
    "            # 变量_modules中。_module的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e99972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0188, -0.1178,  0.0245,  0.1149,  0.0011, -0.2958,  0.1410, -0.1120,\n",
       "          0.3150, -0.0518],\n",
       "        [ 0.1617, -0.1229,  0.1111,  0.1013,  0.0314, -0.2863,  0.1674, -0.0955,\n",
       "          0.2517, -0.1605]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)\n",
    "\n",
    "# tensor([[-0.1229, -0.3086, -0.0750,  0.0414,  0.1376, -0.0072, -0.0623,  0.1302,\n",
    "#           0.0567, -0.1040],\n",
    "#         [-0.0971, -0.2352, -0.0374,  0.0582,  0.1482, -0.1153, -0.1219,  0.0907,\n",
    "#          -0.0910, -0.0503]], grad_fn=<AddmmBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b2b1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        X = self.linear(X)\n",
    "        while X.norm() > 1:\n",
    "            X /= 2\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "083ed153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0137, -0.0107, -0.1359, -0.1292, -0.1642,  0.1579, -0.0298, -0.0687,\n",
       "         -0.0414,  0.0383,  0.0021,  0.1122,  0.1034,  0.0460,  0.0641,  0.1318,\n",
       "          0.0913, -0.0712,  0.0631,  0.0870],\n",
       "        [-0.0264,  0.0202, -0.1371, -0.1727, -0.2293,  0.1529, -0.0139, -0.1404,\n",
       "         -0.0700,  0.0499,  0.0065,  0.1523,  0.1435,  0.0906,  0.0278,  0.1299,\n",
       "          0.1303, -0.1215,  0.0830,  0.1561]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "net = FixedHiddenMLP()\n",
    "net(X)\n",
    "\n",
    "# tensor([[-3.5930e-02, -6.9781e-03, -9.4119e-02,  1.1582e-01,  2.3377e-02,\n",
    "#          -6.6372e-02, -3.2058e-02, -1.2786e-02, -2.3962e-02, -3.1722e-02,\n",
    "#          -1.8784e-01, -9.4819e-05,  2.0893e-01,  2.1778e-01,  1.4351e-01,\n",
    "#          -2.6391e-02,  6.5536e-03,  2.2466e-01, -9.9925e-02,  1.7696e-01],\n",
    "#         [-5.0210e-02, -5.7538e-03, -8.4254e-02,  1.0451e-01,  2.4118e-02,\n",
    "#          -4.9907e-02, -1.8658e-02, -3.4405e-02, -2.3964e-02, -5.3667e-02,\n",
    "#          -1.9062e-01,  7.6478e-03,  2.0308e-01,  2.3180e-01,  1.2236e-01,\n",
    "#          -2.7363e-02,  1.1634e-03,  2.2023e-01, -1.0947e-01,  1.9209e-01]],\n",
    "#        grad_fn=<DivBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0cb9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0388,  0.0290, -0.0526,  0.0514, -0.0501, -0.1435, -0.1622, -0.1392,\n",
       "         -0.1977,  0.0007,  0.0417, -0.0216, -0.0071,  0.0533,  0.0229,  0.0953,\n",
       "         -0.0976, -0.0235,  0.0743, -0.0100],\n",
       "        [ 0.0376,  0.0295, -0.0516,  0.0523, -0.0497, -0.1445, -0.1619, -0.1384,\n",
       "         -0.1969, -0.0015,  0.0407, -0.0220, -0.0069,  0.0526,  0.0213,  0.0954,\n",
       "         -0.0972, -0.0245,  0.0751, -0.0102]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
    "                                 nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)\n",
    "\n",
    "# tensor([[ 0.0388,  0.0290, -0.0526,  0.0514, -0.0501, -0.1435, -0.1622, -0.1392,\n",
    "#          -0.1977,  0.0007,  0.0417, -0.0216, -0.0071,  0.0533,  0.0229,  0.0953,\n",
    "#          -0.0976, -0.0235,  0.0743, -0.0100],\n",
    "#         [ 0.0376,  0.0295, -0.0516,  0.0523, -0.0497, -0.1445, -0.1619, -0.1384,\n",
    "#          -0.1969, -0.0015,  0.0407, -0.0220, -0.0069,  0.0526,  0.0213,  0.0954,\n",
    "#          -0.0972, -0.0245,  0.0751, -0.0102]], grad_fn=<DivBackward0>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d65c2",
   "metadata": {},
   "source": [
    "# 参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05cafcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1822],\n",
       "        [-0.3126]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)\n",
    "\n",
    "# tensor([[-0.1822],\n",
    "#         [-0.3126]], grad_fn=<AddmmBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3518fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3099ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1093],\n",
       "        [-0.1140]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa641f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.3444,  0.3052, -0.3438, -0.1365,  0.2980, -0.2586, -0.1679, -0.1135]])),\n",
       "             ('bias', tensor([-0.2424]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict()\n",
    "\n",
    "# OrderedDict([('weight',\n",
    "#               tensor([[-0.3444,  0.3052, -0.3438, -0.1365,  0.2980, -0.2586, -0.1679, -0.1135]])),\n",
    "#              ('bias', tensor([-0.2424]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "419b47e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83686f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.2424], requires_grad=True)\n",
      "tensor([-0.2424])\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)\n",
    "\n",
    "# <class 'torch.nn.parameter.Parameter'>\n",
    "# Parameter containing:\n",
    "# tensor([-0.2424], requires_grad=True)\n",
    "# tensor([-0.2424])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b03d29ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None\n",
    "\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "379f274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])\n",
    "\n",
    "# ('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
    "# ('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ef85967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2424])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data\n",
    "\n",
    "# tensor([-0.2424])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62d7daa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3489],\n",
       "        [-0.3489]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    block = nn.Sequential(\n",
    "        nn.Linear(4, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 4),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    return block\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f\"block {i}\", block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(\n",
    "    block2(),\n",
    "    nn.Linear(4, 1)\n",
    ")\n",
    "\n",
    "rgnet(X)\n",
    "\n",
    "# tensor([[-0.3489],\n",
    "#         [-0.3489]], grad_fn=<AddmmBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "072982d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)\n",
    "\n",
    "# Sequential(\n",
    "#   (0): Sequential(\n",
    "#     (block 0): Sequential(\n",
    "#       (0): Linear(in_features=4, out_features=8, bias=True)\n",
    "#       (1): ReLU()\n",
    "#       (2): Linear(in_features=8, out_features=4, bias=True)\n",
    "#       (3): ReLU()\n",
    "#     )\n",
    "#     (block 1): Sequential(\n",
    "#       (0): Linear(in_features=4, out_features=8, bias=True)\n",
    "#       (1): ReLU()\n",
    "#       (2): Linear(in_features=8, out_features=4, bias=True)\n",
    "#       (3): ReLU()\n",
    "#     )\n",
    "#     (block 2): Sequential(\n",
    "#       (0): Linear(in_features=4, out_features=8, bias=True)\n",
    "#       (1): ReLU()\n",
    "#       (2): Linear(in_features=8, out_features=4, bias=True)\n",
    "#       (3): ReLU()\n",
    "#     )\n",
    "#     (block 3): Sequential(\n",
    "#       (0): Linear(in_features=4, out_features=8, bias=True)\n",
    "#       (1): ReLU()\n",
    "#       (2): Linear(in_features=8, out_features=4, bias=True)\n",
    "#       (3): ReLU()\n",
    "#     )\n",
    "#   )\n",
    "#   (1): Linear(in_features=4, out_features=1, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "323ac205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2957,  0.2749,  0.1099, -0.2194,  0.4637, -0.1263, -0.3124,  0.3046])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data\n",
    "\n",
    "# tensor([ 0.2957,  0.2749,  0.1099, -0.2194,  0.4637, -0.1263, -0.3124,  0.3046])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a985521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0068,  0.3340, -0.0026, -0.2887]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[1].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76910825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0028, -0.0031,  0.0210, -0.0002]), tensor(0.))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]\n",
    "\n",
    "# (tensor([ 0.0028, -0.0031,  0.0210, -0.0002]), tensor(0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f86161dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]\n",
    "\n",
    "# (tensor([1., 1., 1., 1.]), tensor(0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc03c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3365,  0.4642, -0.1247, -0.1969])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "def init_xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "\n",
    "net[0].apply(init_xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)\n",
    "\n",
    "# tensor([ 0.3365,  0.4642, -0.1247, -0.1969])\n",
    "# tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f64ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000,  7.1099, -7.0694, -6.1635]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape)\n",
    "                        for name, param in m.named_parameters()][0])\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]\n",
    "\n",
    "# tensor([[-0.0000, -0.0000, -0.0000, -0.0000],\n",
    "#         [ 0.0000,  7.1099, -7.0694, -6.1635]], grad_fn=<SliceBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33c76ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a913723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]\n",
    "\n",
    "# tensor([42.,  1.,  1.,  1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33550f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [ 1.0000,  8.1099, -6.0694, -5.1635],\n",
       "        [ 1.0000,  1.0000,  1.0000,  8.5654],\n",
       "        [ 1.0000, -8.3642,  8.0938,  1.0000],\n",
       "        [ 9.6432,  1.0000,  1.0000,  1.0000],\n",
       "        [-8.4329,  1.0000,  1.0000,  1.0000],\n",
       "        [ 1.0000,  6.0261,  1.0000, 10.3409],\n",
       "        [ 8.1057,  8.2111,  1.0000,  1.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70d1973a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a68646c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2248],\n",
       "        [-0.2136]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义共享层\n",
    "shared = nn.Linear(8, 8)\n",
    "\n",
    "# 定义网络\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.ReLU(),\n",
    "    shared,\n",
    "    nn.ReLU(),\n",
    "    shared,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "net(X)\n",
    "\n",
    "# tensor([[-0.2248],\n",
    "#         [-0.2136]], grad_fn=<AddmmBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4e66f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "\n",
    "# tensor([True, True, True, True, True, True, True, True])\n",
    "# tensor([True, True, True, True, True, True, True, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704628a",
   "metadata": {},
   "source": [
    "# 自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56ff2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae7233ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))\n",
    "\n",
    "# tensor([-2., -1.,  0.,  1.,  2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ea3af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ac6d02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.3132e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()\n",
    "\n",
    "# tensor(9.3132e-09, grad_fn=<MeanBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0fc538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units, ))\n",
    "\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight) + self.bias\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "312988e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6056,  1.6645, -0.2851])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a51925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8582, -0.8524,  1.5880],\n",
       "        [ 0.0292, -0.0751,  0.9909],\n",
       "        [-1.7602,  0.3408, -0.6826],\n",
       "        [-2.7443,  0.0341, -0.6046],\n",
       "        [ 0.5380, -0.4133, -0.7976]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7619ef48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.2373,  0.0189,  0.2378],\n",
       "        [ 1.3135, -1.1337,  0.1082],\n",
       "        [ 0.1025,  0.5644,  0.0697],\n",
       "        [ 0.8477, -1.5213, -1.0938],\n",
       "        [-1.7703, -1.2536, -0.9810]], requires_grad=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight\n",
    "\n",
    "# Parameter containing:\n",
    "# tensor([[-1.2373,  0.0189,  0.2378],\n",
    "#         [ 1.3135, -1.1337,  0.1082],\n",
    "#         [ 0.1025,  0.5644,  0.0697],\n",
    "#         [ 0.8477, -1.5213, -1.0938],\n",
    "#         [-1.7703, -1.2536, -0.9810]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7da01358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [0.0995, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))\n",
    "\n",
    "# tensor([[0.0000, 0.0000, 0.0000],\n",
    "#         [0.0995, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78c72297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16.0757],\n",
       "        [ 3.3368]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))\n",
    "\n",
    "# tensor([[16.0757],\n",
    "#         [ 3.3368]], grad_fn=<ReluBackward0>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cf60f5",
   "metadata": {},
   "source": [
    "# 读写文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff9de702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654477f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2\n",
    "\n",
    "# tensor([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356b028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)\n",
    "\n",
    "# (tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b2cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2\n",
    "\n",
    "# {'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a851b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31babc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9580472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()\n",
    "\n",
    "# MLP(\n",
    "#   (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
    "#   (output): Linear(in_features=256, out_features=10, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cfa0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y\n",
    "\n",
    "# tensor([[True, True, True, True, True, True, True, True, True, True],\n",
    "#         [True, True, True, True, True, True, True, True, True, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bed08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
