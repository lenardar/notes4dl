{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5841a250",
   "metadata": {},
   "source": [
    "学习现代卷积神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d77067",
   "metadata": {},
   "source": [
    "# 深度卷积神经网络（AlexNet）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f061ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10),\n",
    "\n",
    "    # Softmax层\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da605b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
      "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
      "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 6400])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 1, 224, 224)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)\n",
    "\n",
    "# Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
    "# ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
    "# Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
    "# ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
    "# Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
    "# ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
    "# Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
    "# ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
    "# Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
    "# ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
    "# Flatten output shape:\t torch.Size([1, 6400])\n",
    "# Linear output shape:\t torch.Size([1, 4096])\n",
    "# ReLU output shape:\t torch.Size([1, 4096])\n",
    "# Dropout output shape:\t torch.Size([1, 4096])\n",
    "# Linear output shape:\t torch.Size([1, 4096])\n",
    "# ReLU output shape:\t torch.Size([1, 4096])\n",
    "# Dropout output shape:\t torch.Size([1, 4096])\n",
    "# Linear output shape:\t torch.Size([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299857fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# 这里使用Fashion-MNIST数据集来训练AlexNet\n",
    "# 由于Fashion-MNIST的图像大小为28*28，且通道数为1，\n",
    "# 因此需要将图像大小调整为224*224，通道数为1。\n",
    "# 这可以通过在数据集上应用转换来实现。\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=False, download=True\n",
    "    , transform=transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3433477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x11896e520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1627, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py\", line 930, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 3616) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 95\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, train_acc, test_acc\n\u001b[32m     94\u001b[39m lr, num_epochs = \u001b[32m0.01\u001b[39m, \u001b[32m10\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[43mtrain_ch6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mtrain_ch6\u001b[39m\u001b[34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n\u001b[32m     65\u001b[39m     optimizer.zero_grad()  \u001b[38;5;66;03m# 清零梯度\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[43ml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 计算梯度\u001b[39;00m\n\u001b[32m     67\u001b[39m     optimizer.step()  \u001b[38;5;66;03m# 更新参数\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# 计算训练集精度\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accury_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accury_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accury_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()  # 计算平均损失\n",
    "            train_l_sum += l.item()\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "lr, num_epochs = 0.0001, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173a70a",
   "metadata": {},
   "source": [
    "云端环境使用cuda训练，修改一下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1871d615",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, train_acc, test_acc\n\u001b[32m    103\u001b[39m lr, num_epochs = \u001b[32m0.01\u001b[39m, \u001b[32m20\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mtrain_ch6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mtrain_ch6\u001b[39m\u001b[34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     40\u001b[39m     device = torch.device(device)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 将模型移动到设备\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 初始化参数\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_weights\u001b[39m(m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/cuda/__init__.py:363\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    359\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    360\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    361\u001b[39m     )\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "\n",
    "        # 使用cuda\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accuracy_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accuracy_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accuracy_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).mean()  # 计算平均损失\n",
    "            train_l_sum += l.item() * y.shape[0]  # 累加损失\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "lr, num_epochs = 0.01, 20\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a80e2e",
   "metadata": {},
   "source": [
    "# 使用块的网络（VGG）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ad0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    \"\"\"VGG块\"\"\"\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ec140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40af28e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    # 卷积层部分\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "\n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(),\n",
    "        # 全连接层部分\n",
    "        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10))\n",
    "\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2757f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 224, 224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',X.shape)\n",
    "\n",
    "# Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
    "# Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
    "# Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
    "# Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
    "# Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
    "# Flatten output shape:\t torch.Size([1, 25088])\n",
    "# Linear output shape:\t torch.Size([1, 4096])\n",
    "# ReLU output shape:\t torch.Size([1, 4096])\n",
    "# Dropout output shape:\t torch.Size([1, 4096])\n",
    "# Linear output shape:\t torch.Size([1, 4096])\n",
    "# ReLU output shape:\t torch.Size([1, 4096])\n",
    "# Dropout output shape:\t torch.Size([1, 4096])\n",
    "# Linear output shape:\t torch.Size([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb742ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# 这里使用Fashion-MNIST数据集来训练AlexNet\n",
    "# 由于Fashion-MNIST的图像大小为28*28，且通道数为1，\n",
    "# 因此需要将图像大小调整为224*224，通道数为1。\n",
    "# 这可以通过在数据集上应用转换来实现。\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=False, download=True\n",
    "    , transform=transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "\n",
    "        # 使用cuda\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accuracy_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accuracy_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accuracy_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).mean()  # 计算平均损失\n",
    "            train_l_sum += l.item() * y.shape[0]  # 累加损失\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "# 开始训练\n",
    "lr, num_epochs = 0.05, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1f53e",
   "metadata": {},
   "source": [
    "# 网络中的网络（NiN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9866e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def nin_block(in_channels, out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1),  # 1x1卷积\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1),  # 1x1卷积\n",
    "        nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5b7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小,10)\n",
    "    nn.Flatten(),\n",
    "    nn.Softmax(dim=1)  # Softmax层\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd6f411a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 10])\n",
      "Softmax output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)\n",
    "\n",
    "# Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
    "# Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
    "# Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
    "# Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
    "# Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
    "# AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
    "# Flatten output shape:\t torch.Size([1, 10])\n",
    "# Softmax output shape:\t torch.Size([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9009294e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    129\u001b[39m     plt.show()\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, train_acc, test_acc\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43mtrain_ch6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mtrain_ch6\u001b[39m\u001b[34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     70\u001b[39m     device = torch.device(device)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 将模型移动到设备\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# 初始化参数\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_weights\u001b[39m(m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/cuda/__init__.py:363\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    359\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    360\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    361\u001b[39m     )\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 定义超参数\n",
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "\n",
    "# 读取Fashion-MNIST数据集\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=False, download=True\n",
    "    , transform=transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "\n",
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "\n",
    "        # 使用cuda\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accuracy_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accuracy_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accuracy_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).mean()  # 计算平均损失\n",
    "            train_l_sum += l.item() * y.shape[0]  # 累加损失\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a3e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 10])\n",
      "Softmax output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def nin_block(in_channels, out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n",
    "        nn.ReLU(),\n",
    "        # 减少了一层1x1卷积\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1),  # 1x1卷积\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小,10)\n",
    "    nn.Flatten(),\n",
    "    nn.Softmax(dim=1)  # Softmax层\n",
    ")\n",
    "\n",
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)\n",
    "\n",
    "# Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
    "# Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
    "# Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
    "# MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
    "# Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
    "# Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
    "# AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
    "# Flatten output shape:\t torch.Size([1, 10])\n",
    "# Softmax output shape:\t torch.Size([1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793df1e1",
   "metadata": {},
   "source": [
    "# 含并行连结的网络（GoogLeNet）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bf05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbad2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模块1\n",
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be59d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = nn.Sequential(\n",
    "    nn.Conv2d(64, 64, kernel_size=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10dad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3 = nn.Sequential(\n",
    "    Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "    Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36ea1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b4 = nn.Sequential(\n",
    "    Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "    Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "    Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "    Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "    Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29cbaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "b5 = nn.Sequential(\n",
    "    Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "    Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "    nn.AdaptiveAvgPool2d((1,1)),\n",
    "    nn.Flatten()\n",
    ")\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10), nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "\n",
    "# 读取Fashion-MNIST数据集\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((96, 96)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=False, download=True\n",
    "    , transform=transforms.Compose([\n",
    "        transforms.Resize((96, 96)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "\n",
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "\n",
    "        # 使用cuda\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accuracy_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accuracy_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accuracy_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).mean()  # 计算平均损失\n",
    "            train_l_sum += l.item() * y.shape[0]  # 累加损失\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aabd75",
   "metadata": {},
   "source": [
    "# 批量规范化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14fe7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # 通过is_grad_enabled来判断当前模式是训练模式还是预测模式\n",
    "    if not torch.is_grad_enabled():\n",
    "        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # 使用全连接层的情况，计算特征维上的均值和方差\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。\n",
    "            # 这里我们需要保持X的形状以便后面可以做广播运算\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # 训练模式下，用当前的均值和方差做标准化\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # 更新移动平均的均值和方差\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta  # 缩放和移位\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5ab0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    # num_features：完全连接层的输出数量或卷积层的输出通道数。\n",
    "    # num_dims：2表示完全连接层，4表示卷积层\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # 非模型参数的变量初始化为0和1\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 如果X不在内存上，将moving_mean和moving_var\n",
    "        # 复制到X所在显存上\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # 保存更新过的moving_mean和moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd2734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(16*4*4, 120), BatchNorm(120, num_dims=2), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bcc3cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2.257, train acc 0.200, test acc 0.199\n",
      "epoch 2, loss 2.128, train acc 0.226, test acc 0.223\n",
      "epoch 3, loss 2.072, train acc 0.227, test acc 0.226\n",
      "epoch 4, loss 2.028, train acc 0.272, test acc 0.268\n",
      "epoch 5, loss 1.983, train acc 0.254, test acc 0.256\n",
      "epoch 6, loss 1.958, train acc 0.252, test acc 0.249\n",
      "epoch 7, loss 1.941, train acc 0.295, test acc 0.296\n",
      "epoch 8, loss 1.924, train acc 0.281, test acc 0.279\n",
      "epoch 9, loss 1.879, train acc 0.302, test acc 0.301\n",
      "epoch 10, loss 1.855, train acc 0.285, test acc 0.283\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([2.2569621520996095,\n",
       "  2.128013939921061,\n",
       "  2.071741628011068,\n",
       "  2.028006018066406,\n",
       "  1.9825226974487304,\n",
       "  1.9583332350413005,\n",
       "  1.9408618341445922,\n",
       "  1.924431886736552,\n",
       "  1.878732918294271,\n",
       "  1.85470066019694],\n",
       " [0.1999,\n",
       "  0.2263,\n",
       "  0.22708333333333333,\n",
       "  0.27168333333333333,\n",
       "  0.2543666666666667,\n",
       "  0.25198333333333334,\n",
       "  0.29523333333333335,\n",
       "  0.28065,\n",
       "  0.3020833333333333,\n",
       "  0.28545],\n",
       " [0.199,\n",
       "  0.2229,\n",
       "  0.2261,\n",
       "  0.2682,\n",
       "  0.2555,\n",
       "  0.2488,\n",
       "  0.2962,\n",
       "  0.2789,\n",
       "  0.3015,\n",
       "  0.2832])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 256\n",
    "\n",
    "# 这里使用Fashion-MNIST数据集数为1。\n",
    "# 这可以通过在数据集上应用转换来实现。\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        # transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=False, download=True\n",
    "    , transform=transforms.Compose([\n",
    "        # transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True\n",
    ")\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accury_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accury_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accury_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss()  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            train_l_sum += l.item() * y.shape[0]  # 累加损失\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b970d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c301b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.926, train acc 0.764, test acc 0.752\n",
      "epoch 2, loss 0.593, train acc 0.793, test acc 0.778\n",
      "epoch 3, loss 0.510, train acc 0.799, test acc 0.784\n",
      "epoch 4, loss 0.464, train acc 0.792, test acc 0.772\n",
      "epoch 5, loss 0.430, train acc 0.817, test acc 0.804\n",
      "epoch 6, loss 0.405, train acc 0.853, test acc 0.837\n",
      "epoch 7, loss 0.385, train acc 0.848, test acc 0.832\n",
      "epoch 8, loss 0.368, train acc 0.846, test acc 0.829\n",
      "epoch 9, loss 0.355, train acc 0.843, test acc 0.829\n",
      "epoch 10, loss 0.343, train acc 0.806, test acc 0.797\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([0.9259359397570293,\n",
       "  0.5929888911247253,\n",
       "  0.5102295838832855,\n",
       "  0.4643275456428528,\n",
       "  0.43007720138231914,\n",
       "  0.40456520841916405,\n",
       "  0.3851431262175242,\n",
       "  0.3683874034086863,\n",
       "  0.35511772917111717,\n",
       "  0.34308586967786153],\n",
       " [0.76425,\n",
       "  0.7925833333333333,\n",
       "  0.7985333333333333,\n",
       "  0.7922,\n",
       "  0.8171666666666667,\n",
       "  0.85265,\n",
       "  0.8478,\n",
       "  0.846,\n",
       "  0.8428166666666667,\n",
       "  0.8062166666666667],\n",
       " [0.7524,\n",
       "  0.7778,\n",
       "  0.7841,\n",
       "  0.7723,\n",
       "  0.804,\n",
       "  0.8365,\n",
       "  0.8324,\n",
       "  0.8294,\n",
       "  0.8294,\n",
       "  0.7968])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 256\n",
    "\n",
    "# 这里使用Fashion-MNIST数据集数为1。\n",
    "# 这可以通过在数据集上应用转换来实现。\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        # transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=False, download=True\n",
    "    , transform=transforms.Compose([\n",
    "        # transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True\n",
    ")\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accury_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accury_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accury_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss()  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            train_l_sum += l.item() * y.shape[0]  # 累加损失\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55854e26",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495bdd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Residual(nn.Module):  #@save\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179e0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3,3)\n",
    "X = torch.rand(4, 3, 6, 6)\n",
    "Y = blk(X)\n",
    "Y.shape\n",
    "\n",
    "# torch.Size([4, 3, 6, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b024701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3,6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape\n",
    "\n",
    "# torch.Size([4, 6, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f40b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7468bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "950f59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fb002f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(b1, b2, b3, b4, b5,\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten(), nn.Linear(512, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341fa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 128, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 512])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)\n",
    "\n",
    "# Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
    "# Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
    "# Sequential output shape:\t torch.Size([1, 128, 28, 28])\n",
    "# Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
    "# Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
    "# AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1])\n",
    "# Flatten output shape:\t torch.Size([1, 512])\n",
    "# Linear output shape:\t torch.Size([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac811c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "lr, num_epochs, batch_size = 0.05, 10, 256\n",
    "\n",
    "# 读取Fashion-MNIST数据集\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((96, 96)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=False, download=True\n",
    "    , transform=transforms.Compose([\n",
    "        transforms.Resize((96, 96)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "\n",
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "\n",
    "        # 使用cuda\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accuracy_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accuracy_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accuracy_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).mean()  # 计算平均损失\n",
    "            train_l_sum += l.item() * y.shape[0]  # 累加损失\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90ded9",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4e21e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def conv_block(input_channels, num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(input_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2184a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, input_channels, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layer = []\n",
    "        for i in range(num_convs):\n",
    "            layer.append(conv_block(\n",
    "                num_channels * i + input_channels, num_channels))\n",
    "        self.net = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            # 连接通道维度上每个块的输入和输出\n",
    "            X = torch.cat((X, Y), dim=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009466c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 3, 10)\n",
    "X = torch.randn(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "Y.shape\n",
    "\n",
    "# torch.Size([4, 23, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1b6e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(input_channels, num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
    "        nn.Conv2d(input_channels, num_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc45b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(23, 10)\n",
    "blk(Y).shape\n",
    "\n",
    "# torch.Size([4, 10, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3a56f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04f38699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_channels为当前的通道数\n",
    "num_channels, growth_rate = 64, 32\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
    "blks = []\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    blks.append(DenseBlock(num_convs, num_channels, growth_rate))\n",
    "    # 上一个稠密块的输出通道数\n",
    "    num_channels += num_convs * growth_rate\n",
    "    # 在稠密块之间添加一个转换层，使通道数量减半\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        blks.append(transition_block(num_channels, num_channels // 2))\n",
    "        num_channels = num_channels // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55775722",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    b1, *blks,\n",
    "    nn.BatchNorm2d(num_channels), nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(num_channels, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 256\n",
    "\n",
    "# 读取Fashion-MNIST数据集\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((96, 96)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='../data/FashionMNIST', train=False, download=True\n",
    "    , transform=transforms.Compose([\n",
    "        transforms.Resize((96, 96)),  # 调整图像大小\n",
    "        transforms.Grayscale(num_output_channels=1),  # 确保通道数=1\n",
    "        transforms.ToTensor()  # 转换为张量\n",
    "    ])\n",
    ")\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "\n",
    "# 定义准确率计算函数\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "\n",
    "        # 使用cuda\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "            net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    \n",
    "    # 定义正确预测的数量和总样本数\n",
    "    accuracy_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # 如果X是一个列表，则将其转换为张量\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 计算预测结果\n",
    "            y_hat = net(X)\n",
    "            # 累加正确预测的数量\n",
    "            accuracy_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    return accuracy_sum / n  # 返回精度\n",
    "\n",
    "# 计算训练集和测试集的精度，训练集损失函数\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device=None):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    # 将模型移动到指定设备\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.backends.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    net.to(device)  # 将模型移动到设备\n",
    "\n",
    "    # 初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")  # 损失函数\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 优化器\n",
    "\n",
    "    # 定义列表存储损失函数，训练集精度和测试集精度\n",
    "    train_loss, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()  # 设置为训练模式\n",
    "        train_l_sum, n = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).mean()  # 计算平均损失\n",
    "            train_l_sum += l.item() * y.shape[0]  # 累加损失\n",
    "            n += y.shape[0]\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 计算梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_loss.append(train_l_sum / n)\n",
    "\n",
    "        # 计算训练集精度\n",
    "        train_acc.append(evaluate_accuracy(train_iter, net, device))\n",
    "\n",
    "        # 计算测试集精度\n",
    "        test_acc.append(evaluate_accuracy(test_iter, net, device))\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {train_loss[-1]:.3f}, '\n",
    "              f'train acc {train_acc[-1]:.3f}, '\n",
    "              f'test acc {test_acc[-1]:.3f}')\n",
    "    \n",
    "    # 使用plt原生图\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='train loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc, label='train acc')\n",
    "    plt.plot(range(1, num_epochs + 1), test_acc, label='test acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, train_acc, test_acc\n",
    "\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, \"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
